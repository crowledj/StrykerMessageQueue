

Write a brief design document (1-2 pages) explaining your approach:
- Key design decisions, trade-offs, and considerations.
- Choices regarding libraries or technologies used (e.g.,
why asyncio.Queue vs. other options).

o Provide a reflection on your use of ChatGPT or other resources:
- Which parts did you use it for?
- What were the most challenging aspects?
- What would you improve if given more time?


Question 1. 
(i)

I designed the project folder and file structure as shown below,

project-root/  (asycnmsglib)
│
├── message_queue_lib/  ('mypythonlib')
│   ├── __init__.py
│   ├── myfunctions.py   (message_queue implementation)
│   ├── setup.py
│
├── service_publish/
│   ├── main.py
│   ├── requirements.txt
    ├── test_service_publish.py 
│
├── service_subscribe/
│   ├── main.py
│   ├── websocket_manager.py
│   ├── requirements.txt
├   ├── test_service_subscribe.py 
│
└── run_all.sh          # Bash script to run everything


This structure ensures:

Modularity: Each service and library is independent and reusable.
Scalability: Easy to add more services or extend functionality.
Testability: Clear separation of unit and integration tests.

In this structure also the message_queue_lib/ directory can be shared across services.


Question 1.


(ii) 

Why I picked the tolls/libs I did :

I decided to go with using asyncio instead of other related async libraries (like ones that use threading or multiprocessing)
as asyncio is optimized for handling I/O-bound  network code, which is central to this Message Queue project involving message queues 
and WebSocket communication.So it efficiently handles many concurrent tasks (e.g., publishing/subscribing messages, processing WebSocket data).
I wanted to use FastAPI for the services in the project and read online that asynio was a great choice for integrationg with this.

ie. Since FastAPI is designed around asynchronous programming and so it works seamlessly with asyncio.

Also its built into the python standard library and doesnt require any manual installions. This means also that it 
has  a large and thriving Ecosystem and Community Support
Asyncio has a large ecosystem of tools, libraries, and community support that competing libs dont have including:
WebSocket Libraries (like websockets), Testing Frameworks (like pytest-asyncio) and tools for debugging, learning, and extending functionality.

Additionally I decided to use asyncio.Queue for the message queue library as it provides a simple and efficient way to manage message delivery.


Trade Offs and consideratins :


The project structure, libraries, and implementations were chosen based on balancing scalability, maintainability, 
simplicity, and performance while considering potential trade-offs. This is my overview of the considerations and trade-offs:

A) Project Structure
Choice: Modularized services (service_publish, service_subscribe, etc.) with clear boundaries.

Trade-offs:
Advantages:

Encourages separation of concerns, making each service easier to develop, test, and maintain.
Services can be independently scaled or replaced without affecting others.
Aligns with modern microservices best practices.

Disadvantages:

Increased complexity in deployment and communication between services.
Requires additional effort to manage inter-service dependencies (e.g., message queues, APIs).


B) Libraries vs. In-House Implementation
Why libraries:

Chosen for critical tasks (e.g., FastAPI for APIs, asyncio for concurrency).
Avoids "reinventing the wheel" for complex features like async support.
Why in-house implementation:

Custom MessageQueue to simplify dependency management and enable full control over the queue logic.
Trade-offs:

-Libraries are well-tested and robust, whereas custom implementations require extensive testing.
-Less flexibility for future expansion compared to established third-party tools.



C) Setup,install and running of the Development Environment

Choice: Virtual environments and a run_all.sh script for reproducibility.

Advantages:

Isolates dependencies, reducing the risk of version conflicts.
Easy setup for new developers.
Much less complex to create and manage than a dockerised application (given time contraints and large project scope)

Trade-offs:

Requires all contributors to use the same setup to avoid discrepancies.
Shell scripts may need adaptation for cross-platform compatibility.



 Q.2.  Reflection on the use of AI assistants  (ChatGPT):

I used ChatGPT to generate the initial design document and outline the project structure. It helped in brainstorming ideas 
and organizing the project layout. The most challenging aspect was ensuring the modularity and independence of each 
service and library. If given more time, I would improve the error handling and logging mechanisms to enhance the
 robustness of the system. Additionally, I would explore more advanced features like message acknowledgments and 
 dead-letter queues for better message delivery guarantees.

 ChatGPT was helpful in giving code snippets or single functionality files but not of course the whole project code, or even 
 how in terms of code the services would interact with each other and messaged queue and how to test all of this together.

 So I used chatGPT for certain aspects of the codebase, like what the websocket functionality would look like in the subscribe service
 and to explain aspects of that and other specific functionalities.
 Then I would link the functionalities together myself and fill in the missing pieces both inside the code files and between them.

 CHatGPT was also quite helpful in debugging issues I came upon to get to fixing these while also gaining the functionality I 
 was looking to achieve.



